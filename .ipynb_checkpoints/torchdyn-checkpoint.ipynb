{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7357cda9-067d-481d-a927-266b698af2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdyn.core import NeuralODE\n",
    "from BertODE.bertode import RobertaForMaskedLM\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.roberta.configuration_roberta import RobertaConfig\n",
    "from transformers.trainer_pt_utils import LabelSmoother\n",
    "\n",
    "from TrainDatasets.oscar import OSCARDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b24ec1c-4c68-4a1d-a779-7d34e9479fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4b3c33-a98c-4e65-98a3-f2e341df61dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021a030-e598-47b8-a3b2-e4f612e93019",
   "metadata": {},
   "source": [
    "TODO: Subclass roberta model such that the encoder residual connections are ODEs\n",
    "\n",
    "Found: https://github.com/huggingface/transformers/blob/v4.19.0/src/transformers/models/roberta/modeling_roberta.py#L286 subclass this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f383ff29-d5ab-4c40-8c1d-2d341d279974",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(100, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (neuralODE): Neural ODE:\n",
       "              \t- order: 1        \n",
       "              \t- solver: Tsitouras45()\n",
       "              \t- adjoint solver: Tsitouras45()        \n",
       "              \t- tolerances: relative 0.001 absolute 0.001        \n",
       "              \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "              \t- num_parameters: 590592        \n",
       "              \t- NFE: 0.0\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig()\n",
    "model = RobertaForMaskedLM(config).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a48e99-c2eb-46bb-89d6-233ef3f3750d",
   "metadata": {},
   "source": [
    "Thanks documentation! https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/text-transformers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e404d97f-9f90-4145-b666-e5d63adefe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_span = torch.linspace(0, 1, 2)\n",
    "t_span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a9ad2-c730-4a04-8b17-a79c2664c0d3",
   "metadata": {},
   "source": [
    "BERT won't work since it needs NSP implemented and I'm too lazy to do anything other than MLM. We can just use roberta for masked LM which only needs MLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de41a42-6ed3-4f00-a731-95972d203526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(LightningModule):\n",
    "    #label_smoothing_factor = 0.0\n",
    "    \n",
    "    def __init__(self, t_span:torch.Tensor, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model, self.t_span = model, t_span\n",
    "        #self.label_smoother = LabelSmoother(epsilon=self.label_smoothing_factor)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.model(**inputs)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        print(f\"batch {batch_idx}: {batch}\")\n",
    "\n",
    "        \n",
    "        ''' MODEL_ODE\n",
    "        labels = batch.pop(\"labels\")\n",
    "        t_eval, y_hat = self.model(batch, self.t_span)\n",
    "        \n",
    "        outputs = y_hat[-1] # select last point of solution trajectory\n",
    "        loss = self.label_smoother(outputs, labels)\n",
    "        '''\n",
    "        \n",
    "        # if we include labels then the model will auto calculate loss\n",
    "        outputs = self.model(**batch)\n",
    "        \n",
    "        \n",
    "        print(f\"outputs: {outputs}\")\n",
    "        return {'loss': outputs.loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6564c78c-7818-4ddd-988f-73f4173e1a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TrainDatasets.oscar.OSCARDataModule at 0x22c73cb9ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = OSCARDataModule(AutoTokenizer.from_pretrained(model_name))\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb435405-bdf6-4c8c-9c81-531a4db051c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(\n",
       "  (model): RobertaForMaskedLM(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(100, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (neuralODE): Neural ODE:\n",
       "                \t- order: 1        \n",
       "                \t- solver: Tsitouras45()\n",
       "                \t- adjoint solver: Tsitouras45()        \n",
       "                \t- tolerances: relative 0.001 absolute 0.001        \n",
       "                \t- adjoint tolerances: relative 0.0001 absolute 0.0001        \n",
       "                \t- num_parameters: 590592        \n",
       "                \t- NFE: 0.0\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (decoder): Linear(in_features=768, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(t_span, model)\n",
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b69dea-55b5-4b4f-99ec-4ef95155700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\weipy\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1812: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\weipy\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:131: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "C:\\Users\\weipy\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(min_epochs=1, max_epochs=5)\n",
    "trainer.fit(learn, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
