{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db5df78-ec48-47d7-ab8b-7133cdf8aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roberta import RobertaModel\n",
    "from transformers import RobertaTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152933a4-3bc7-4fef-8054-f537377c9816",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtensor\u001b[49m([[    \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m31414\u001b[39m,     \u001b[38;5;241m6\u001b[39m,   \u001b[38;5;241m127\u001b[39m,  \u001b[38;5;241m2335\u001b[39m,    \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m11962\u001b[39m,     \u001b[38;5;241m2\u001b[39m]]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: tensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]])}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "#tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "#inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "inputs = {'input_ids': torch.tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     2]]), 'attention_mask': torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c38d06-26d4-493b-b5dc-0cdbb13c0744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d89b44-1ee5-426a-ae93-f8b717e3fdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4a475a-aa13-45bd-aaea-c3a4e2849b09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0478,  0.0886, -0.0098,  ..., -0.0544, -0.0672, -0.0039],\n",
       "         [-0.0712,  0.0150, -0.1299,  ...,  0.0638,  0.0296, -0.0860],\n",
       "         [ 0.0906,  0.1437,  0.0828,  ...,  0.0509, -0.0320, -0.0490],\n",
       "         ...,\n",
       "         [ 0.0853,  0.2155,  0.0849,  ..., -0.1150,  0.0330, -0.0790],\n",
       "         [ 0.1679,  0.1288,  0.0065,  ...,  0.0367, -0.0631,  0.0276],\n",
       "         [-0.0436,  0.0892, -0.0389,  ..., -0.0957, -0.0744, -0.0284]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-3.2083e-03, -2.1940e-01, -2.1088e-01, -7.6721e-02,  1.2052e-01,\n",
       "          2.0488e-01,  2.6070e-01, -8.4344e-02, -7.2521e-02, -1.7025e-01,\n",
       "          2.1089e-01, -2.1008e-02, -8.2023e-02,  1.0177e-01, -1.4424e-01,\n",
       "          4.9201e-01,  2.1202e-01, -4.5743e-01,  3.5992e-02, -1.5410e-02,\n",
       "         -2.7218e-01,  8.2779e-02,  4.7007e-01,  3.3553e-01,  1.1576e-01,\n",
       "          6.0713e-02, -1.3375e-01, -1.2829e-02,  1.8398e-01,  2.2060e-01,\n",
       "          2.8606e-01,  6.4952e-02,  8.1128e-02,  2.3803e-01, -2.4037e-01,\n",
       "          6.3118e-02, -3.1076e-01,  2.3125e-02,  2.6080e-01, -1.8651e-01,\n",
       "         -7.9452e-02,  1.6443e-01,  2.1045e-01, -1.1840e-01, -1.1290e-01,\n",
       "          4.0572e-01,  2.5643e-01,  1.2402e-02, -1.4012e-01, -9.0373e-02,\n",
       "         -3.5431e-01,  3.3689e-01,  2.8484e-01,  1.9504e-01, -3.8898e-03,\n",
       "          5.9286e-02, -1.4538e-01,  2.5130e-01, -8.0821e-02, -9.2138e-02,\n",
       "         -1.1770e-01, -2.0288e-01, -1.3296e-02, -5.4601e-02,  2.9600e-02,\n",
       "         -1.4047e-01,  9.0024e-02, -1.4624e-01, -1.4190e-01,  5.4813e-02,\n",
       "         -8.5831e-02,  1.5300e-01,  1.6914e-01, -2.9596e-01, -2.9194e-01,\n",
       "          4.4366e-02, -5.8714e-01, -9.9223e-02,  2.9637e-01,  4.2659e-01,\n",
       "         -1.2049e-01,  1.8538e-01,  3.9121e-02,  2.1080e-01, -1.1053e-04,\n",
       "         -4.0333e-02, -3.0292e-02, -1.1374e-01,  1.9258e-01,  2.7085e-01,\n",
       "         -1.9872e-01, -3.7765e-01,  6.6629e-02,  1.1977e-02, -9.2962e-02,\n",
       "          2.1994e-02, -2.3806e-02, -9.6243e-02, -1.5413e-01, -1.6730e-01,\n",
       "          5.4596e-02, -2.6967e-01, -1.4077e-01,  2.6593e-01, -3.2843e-02,\n",
       "         -1.9712e-01, -7.7841e-03,  3.1161e-01,  7.4520e-02, -1.1691e-01,\n",
       "         -1.9002e-01,  4.2707e-01,  3.0891e-01,  1.9905e-04,  3.0902e-03,\n",
       "          1.7533e-01,  1.3256e-01, -2.9231e-01,  4.0937e-01, -3.1320e-01,\n",
       "         -1.7837e-02, -9.4238e-02,  1.1146e-01,  1.5994e-01, -2.2116e-01,\n",
       "          2.8568e-01,  1.3704e-01,  2.6840e-01,  1.8057e-01,  1.0697e-01,\n",
       "         -2.9501e-02,  1.4506e-01, -9.1473e-02,  1.3043e-01,  2.3266e-01,\n",
       "          1.1518e-01, -8.2935e-03, -3.2977e-01, -2.0575e-01,  2.6943e-01,\n",
       "          3.4101e-01,  1.5848e-01, -5.1063e-02,  1.8997e-01,  8.5725e-02,\n",
       "          2.2128e-01,  1.4372e-01, -4.1022e-01,  4.1918e-02,  3.5082e-01,\n",
       "          9.5941e-02,  1.5608e-01, -7.9715e-02, -2.8092e-01, -2.6411e-01,\n",
       "         -8.8306e-02,  5.0072e-02, -3.2875e-01, -1.3208e-01,  3.6530e-01,\n",
       "          2.1469e-02, -9.1301e-03, -1.4111e-01, -2.4637e-01, -2.3832e-02,\n",
       "         -1.2317e-01,  1.0649e-02,  1.1023e-01, -8.7270e-02, -4.0457e-01,\n",
       "         -8.6754e-02, -5.5748e-01, -1.0560e-01,  1.7113e-01, -3.2426e-01,\n",
       "          2.5368e-01, -2.7681e-01,  1.0262e-01,  4.0273e-01,  4.1042e-02,\n",
       "         -6.0417e-03, -1.8827e-01, -1.8964e-02,  9.2425e-02,  3.3184e-01,\n",
       "          2.4544e-01, -4.0065e-01,  1.1210e-01,  1.4380e-01,  2.5446e-01,\n",
       "          1.4272e-01, -5.5810e-02, -1.2864e-01,  1.5657e-01, -2.0099e-01,\n",
       "          1.7956e-01, -2.2109e-01,  1.8028e-01, -2.5524e-01, -2.1461e-01,\n",
       "          2.8902e-01, -3.9955e-01, -2.0351e-02,  8.7447e-02,  2.6895e-01,\n",
       "          1.2951e-02, -3.0363e-02, -7.7951e-02,  1.2212e-01,  1.9052e-01,\n",
       "          1.3431e-01, -3.8683e-01,  2.6582e-01, -2.7070e-02, -2.0792e-02,\n",
       "         -2.9300e-02,  1.6273e-01,  2.4574e-01,  9.6820e-02, -3.8570e-01,\n",
       "         -1.4093e-01,  1.1557e-01,  2.8804e-01, -2.2367e-01,  1.6416e-01,\n",
       "         -2.8154e-01, -3.9087e-01, -1.5021e-01,  2.1086e-01,  2.3105e-01,\n",
       "          1.6857e-01, -2.7287e-01,  1.6306e-01, -9.6196e-02, -4.2966e-01,\n",
       "         -3.6699e-01, -1.0738e-01,  2.5007e-01,  1.7285e-01,  1.8841e-01,\n",
       "          2.3728e-01,  3.9772e-02,  1.2035e-01,  1.4498e-01,  1.5580e-01,\n",
       "         -1.5020e-01,  1.9035e-01, -3.5627e-01, -5.8517e-02, -2.6624e-01,\n",
       "         -1.9203e-01, -1.9466e-01,  3.9838e-01, -2.3064e-01,  2.3329e-01,\n",
       "          3.8728e-01, -3.0407e-01, -1.1507e-01,  1.4859e-01,  9.1981e-02,\n",
       "          9.4698e-02, -1.1759e-01,  1.9530e-01,  1.4820e-01, -1.0942e-01,\n",
       "          2.5250e-01,  2.3120e-03,  2.5350e-01,  1.6860e-01,  8.7136e-02,\n",
       "          1.3513e-01,  1.2709e-01, -1.4862e-01,  6.0751e-02,  9.3345e-03,\n",
       "         -1.5235e-02, -2.3177e-01, -1.5835e-01,  2.3159e-01, -5.2097e-02,\n",
       "          2.3692e-02, -1.7081e-01, -1.1216e-01,  2.9000e-02,  4.0367e-01,\n",
       "         -3.5810e-01,  2.5118e-01,  7.6397e-02,  1.5772e-01, -2.4908e-01,\n",
       "         -2.2593e-01,  8.8132e-02,  1.7857e-01, -4.1115e-01,  1.0124e-02,\n",
       "          1.7034e-01,  9.3064e-02,  2.0605e-01,  2.6011e-01,  8.8563e-03,\n",
       "         -1.1599e-01,  4.9098e-01, -1.6107e-01, -1.0854e-01,  2.5703e-01,\n",
       "         -2.7082e-01, -2.7938e-01,  2.4896e-01, -2.8771e-02,  2.9932e-01,\n",
       "          1.2622e-01,  5.4038e-02,  7.4917e-02, -6.0018e-01,  6.1034e-02,\n",
       "         -4.5302e-01,  9.6109e-03,  2.2219e-02, -8.2516e-02, -1.9849e-01,\n",
       "          1.4898e-01,  2.9653e-01, -2.5667e-01, -2.8793e-02,  1.8863e-01,\n",
       "          6.9257e-02, -1.2353e-01,  4.7548e-01, -1.0399e-02,  2.1192e-01,\n",
       "         -5.5704e-02,  2.7205e-01, -2.1447e-01,  2.6845e-01, -2.7371e-01,\n",
       "         -7.9793e-02,  1.9678e-02,  7.9384e-02,  6.9016e-02, -6.2468e-02,\n",
       "         -3.3971e-01,  2.3516e-01, -7.9372e-03, -5.4151e-02, -3.6996e-02,\n",
       "          1.0210e-01,  8.3840e-04,  4.8332e-02,  5.8442e-02,  3.1268e-01,\n",
       "          2.2963e-01, -1.5988e-02, -3.7113e-01, -2.7166e-02, -8.3582e-02,\n",
       "          3.8697e-02,  4.8938e-02, -1.5783e-02,  4.3969e-01, -8.1168e-02,\n",
       "          3.5309e-03, -1.4284e-01,  2.6100e-01,  2.1125e-01,  1.2627e-01,\n",
       "          1.2150e-01,  5.6126e-02,  1.2790e-01, -5.3467e-02, -7.7731e-03,\n",
       "         -1.5671e-01, -2.3348e-01, -2.7533e-01,  2.0882e-01, -2.3905e-01,\n",
       "         -1.6444e-01,  1.6090e-01,  2.1307e-01, -1.5447e-01,  1.4451e-01,\n",
       "          3.0499e-01,  1.0366e-01, -1.4900e-01,  2.6629e-01, -1.0861e-01,\n",
       "          9.7824e-02,  3.1754e-01, -1.5510e-02,  1.7810e-01,  4.9086e-01,\n",
       "          2.1100e-01, -3.6921e-01, -3.9460e-02, -2.1250e-01, -2.9532e-03,\n",
       "          2.3747e-01, -1.4730e-01,  2.0255e-01,  3.8513e-01,  3.0637e-01,\n",
       "          4.5606e-01,  8.6698e-03, -1.3313e-01,  8.3101e-02,  2.1972e-01,\n",
       "          3.5209e-02, -1.5206e-01, -1.8271e-01,  2.5397e-01,  5.9857e-02,\n",
       "         -1.4193e-01, -3.8307e-02, -1.4553e-01,  4.7165e-02, -1.3325e-01,\n",
       "         -3.9433e-01,  4.2436e-02,  1.9429e-01, -4.8001e-01,  8.4262e-02,\n",
       "         -2.7683e-01,  3.6440e-02, -2.3495e-01,  2.1043e-01, -2.1483e-01,\n",
       "         -1.1695e-01,  3.9920e-01, -8.2238e-02,  5.3366e-02, -1.8199e-01,\n",
       "         -1.4275e-01,  2.0019e-02,  1.1507e-02, -3.6021e-02, -2.6190e-02,\n",
       "          3.3418e-01, -1.3056e-01,  3.2988e-02,  2.2499e-02,  2.0725e-01,\n",
       "         -3.8817e-02,  1.9868e-01,  2.0599e-02, -1.3215e-01, -3.7478e-01,\n",
       "          1.3769e-01, -1.9972e-01, -4.2155e-01, -3.7575e-01,  3.5446e-01,\n",
       "         -1.2160e-01, -2.4805e-01, -2.1167e-01, -2.5744e-01,  7.9576e-02,\n",
       "          1.7727e-01,  4.6106e-01, -3.8363e-01, -8.9918e-02,  4.6798e-01,\n",
       "         -6.3311e-02, -1.8311e-01,  2.9651e-01,  1.8038e-01, -3.3584e-01,\n",
       "          3.3358e-01,  2.5996e-01, -4.4390e-02,  2.1432e-02,  5.1450e-01,\n",
       "          1.2765e-01,  2.0913e-01, -2.3102e-01,  4.4982e-01, -2.2196e-01,\n",
       "          3.2071e-01, -1.4369e-01, -2.1302e-01, -2.2435e-01, -5.3516e-03,\n",
       "          3.3233e-01,  1.8082e-01, -4.2011e-01, -1.1286e-01,  4.2059e-02,\n",
       "          3.3800e-01, -3.8471e-01, -9.5194e-02,  1.4146e-02, -3.5604e-01,\n",
       "          1.0313e-01,  9.5098e-02,  2.2574e-01, -3.7865e-01,  3.6247e-03,\n",
       "          4.0502e-01, -3.0943e-01,  1.2550e-01,  3.0371e-01,  8.1005e-02,\n",
       "          3.3761e-01, -4.3828e-02, -3.5592e-03,  4.5577e-02, -2.2371e-01,\n",
       "         -3.7315e-02,  1.3860e-01,  5.5346e-01,  1.4818e-01, -3.8170e-01,\n",
       "          8.5319e-02,  2.4381e-01, -1.7700e-01,  3.0341e-01, -8.3246e-02,\n",
       "         -5.3749e-02,  2.6875e-01, -4.7404e-02,  1.4566e-01, -8.5108e-02,\n",
       "         -2.3477e-01, -3.0237e-01,  3.7206e-01, -2.1425e-01, -1.1400e-01,\n",
       "         -1.5839e-01, -1.1716e-01, -1.4141e-01,  3.6058e-02, -3.9509e-01,\n",
       "          3.3778e-01,  1.2326e-01, -2.1119e-01, -9.7114e-02, -9.1938e-02,\n",
       "         -1.6368e-01, -2.2534e-01, -2.6148e-01,  4.4172e-01, -1.5848e-01,\n",
       "         -4.5032e-01,  2.5770e-01,  2.4804e-02,  3.4088e-01,  3.5758e-02,\n",
       "          1.0179e-01, -4.3535e-02,  1.3006e-01,  1.0202e-01, -1.2319e-01,\n",
       "          2.6838e-01,  5.6350e-02, -5.5955e-01, -1.2166e-01, -2.0871e-01,\n",
       "          7.0198e-02,  1.9283e-01, -3.4027e-01,  1.8359e-02,  3.0427e-02,\n",
       "          1.4175e-01,  2.0520e-02, -1.1092e-01, -7.2368e-02,  4.0556e-01,\n",
       "          2.3859e-01,  2.8483e-01,  9.0411e-02,  2.4168e-01, -1.5583e-02,\n",
       "         -3.3556e-01,  3.5719e-02,  8.4716e-02, -1.9951e-01,  4.2450e-01,\n",
       "         -1.0325e-01, -3.9120e-01, -6.8124e-02,  3.9697e-01,  1.1035e-01,\n",
       "         -2.6056e-02, -4.7428e-02,  2.0151e-01,  1.6093e-01, -1.3766e-01,\n",
       "          1.9095e-01, -4.2122e-02, -1.4172e-01, -1.1627e-01,  8.0168e-02,\n",
       "         -2.1798e-01,  4.4219e-02, -1.4472e-01, -9.5638e-03, -2.0081e-01,\n",
       "          7.9597e-03, -1.9085e-01,  2.5598e-01, -3.3713e-01,  1.1407e-01,\n",
       "          7.0708e-02,  2.9457e-01, -3.4398e-01, -1.6568e-01, -6.8814e-02,\n",
       "          1.5692e-01,  2.6861e-01,  3.4846e-01,  2.1363e-02,  1.2183e-02,\n",
       "         -1.5440e-01, -2.5803e-01,  7.1844e-02, -1.9390e-01,  1.3984e-01,\n",
       "          7.0863e-02,  2.6211e-01, -3.0336e-01, -1.8847e-01,  2.2263e-01,\n",
       "         -1.0745e-01, -1.5428e-01,  4.0873e-01,  2.4101e-01,  2.1457e-01,\n",
       "          2.5258e-02,  2.4745e-01,  3.0405e-02, -1.7431e-01, -1.2609e-01,\n",
       "         -2.5028e-01,  7.9450e-02, -7.4164e-02, -5.3013e-02, -6.4149e-02,\n",
       "         -1.0449e-01, -2.0651e-01, -1.6621e-01,  1.3898e-01,  1.4613e-01,\n",
       "          3.6762e-02, -5.0540e-02, -2.2787e-02, -2.7661e-01,  2.9619e-01,\n",
       "          2.0211e-02,  7.4367e-02, -6.5166e-02,  2.9048e-02, -1.4591e-01,\n",
       "          2.4087e-01,  2.1074e-01,  9.0950e-02, -1.9921e-01, -4.8711e-02,\n",
       "         -2.8255e-01, -3.6132e-01,  6.1972e-02,  1.3865e-01,  1.0557e-01,\n",
       "         -6.8828e-02, -2.8253e-01, -1.0248e-02, -1.4579e-01,  1.7499e-01,\n",
       "          1.5391e-02, -1.5322e-01, -8.2757e-02, -5.3386e-02, -5.5117e-02,\n",
       "          7.9734e-02, -2.1771e-01, -1.8813e-01, -1.1873e-01, -6.5332e-02,\n",
       "         -7.3576e-02,  3.5305e-01, -4.6619e-02,  2.8208e-01, -1.4859e-01,\n",
       "          1.0735e-03, -1.6637e-01,  1.1365e-01, -6.2794e-02,  6.2111e-02,\n",
       "          2.7882e-01, -4.4071e-01, -1.6083e-01, -2.9695e-03, -2.1326e-01,\n",
       "         -1.6536e-01, -6.1523e-02, -3.7208e-02,  2.3069e-01, -3.4058e-01,\n",
       "          2.3236e-01, -1.2023e-01,  1.9255e-01, -7.2060e-02, -2.5519e-01,\n",
       "         -1.5923e-01,  1.6881e-02,  2.4711e-01, -3.4725e-01, -2.3262e-01,\n",
       "         -2.7701e-01, -1.0317e-01, -9.3272e-02, -2.6039e-01,  4.2547e-01,\n",
       "         -1.0798e-01, -7.4447e-02,  1.9067e-02,  4.4333e-01,  2.0667e-01,\n",
       "          1.4671e-01,  2.1272e-01, -1.5556e-02,  2.9830e-02,  1.1363e-01,\n",
       "         -4.5824e-01,  2.2959e-01, -2.3105e-01, -1.1901e-01, -2.5509e-03,\n",
       "          8.7938e-02, -2.8578e-02,  1.0000e-02, -1.3353e-01, -1.1202e-01,\n",
       "          2.1694e-01, -3.6830e-01, -3.1860e-02,  2.5587e-01,  1.5419e-01,\n",
       "         -2.5011e-01,  4.0122e-02,  1.1360e-01,  3.7682e-01,  1.0048e-01,\n",
       "         -2.2502e-01,  1.2753e-01, -3.4334e-01, -4.1958e-02, -1.9138e-01,\n",
       "         -2.9233e-01,  1.5540e-01, -6.1172e-02,  7.5229e-02, -8.8815e-02,\n",
       "         -2.9441e-01,  2.1590e-01, -5.9937e-02, -7.0518e-02,  4.1725e-01,\n",
       "          3.5135e-02, -1.3039e-01,  1.5322e-01,  6.3149e-03,  7.2841e-03,\n",
       "         -1.0152e-01,  2.6193e-01,  2.1660e-01, -2.7404e-01,  1.4459e-01,\n",
       "         -1.3454e-01, -3.1701e-02, -1.1210e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
