{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c89659-fa00-4abe-abdc-baf991481c7f",
   "metadata": {},
   "source": [
    "Root solver that implements broyden root finding and accepts weight tied residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e57e9a6-c3fa-4b40-a431-b04ebc5ec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdyn.numerics.root import BroydenFull, TerminationCondition, NaiveSearch, batch_jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7ecaf8-12e4-4e18-bbd7-1ef065c5cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broyden_dz_nuts(g, z, alpha=0.1, f_tol=1e-2, f_rtol=1e-1, x_tol=1e-2, x_rtol=1, maxiters=100):\n",
    "\n",
    "    tc = TerminationCondition(f_tol=f_tol, f_rtol=f_rtol, x_tol=x_tol, x_rtol=x_rtol)\n",
    "    solver = BroydenFull\n",
    "\n",
    "    # first evaluation of g(z)\n",
    "    geval = g(z)\n",
    "\n",
    "    # initialize inverse jacobian J^-1g(z)\n",
    "    J_inv = batch_jacobian(g, z).pinverse()\n",
    "\n",
    "    iteration = 0\n",
    "    while iteration <= maxiters:\n",
    "        iteration += 1\n",
    "\n",
    "        # solver step\n",
    "        z, dz, geval, J_inv = solver.step(g=g, z0=z, J_inv=J_inv, geval_old=geval, alpha=alpha)\n",
    "\n",
    "        # line search subroutines\n",
    "        line_searcher = NaiveSearch(g, geval, dz, z)\n",
    "        alpha, phi = line_searcher.search()\n",
    "\n",
    "        # full termination check\n",
    "        code = tc.check(geval, z, dz)\n",
    "        if code > 0: break\n",
    "\n",
    "    return z, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1f440e-430d-4d14-8dca-bd8c2191c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers import broyden, anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ca05f2-64b2-4e1a-90ca-821cae75d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anderson_resnet(f, x0, m=5, lam=1e-4, max_iter=50, tol=1e-2, beta = 1.0):\n",
    "    \"\"\" Anderson acceleration for fixed point iteration. \"\"\"\n",
    "    bsz, d, H, W = x0.shape\n",
    "    X = torch.zeros(bsz, m, d*H*W, dtype=x0.dtype, device=x0.device)\n",
    "    F = torch.zeros(bsz, m, d*H*W, dtype=x0.dtype, device=x0.device)\n",
    "    X[:,0], F[:,0] = x0.view(bsz, -1), f(x0).view(bsz, -1)\n",
    "    X[:,1], F[:,1] = F[:,0], f(F[:,0].view_as(x0)).view(bsz, -1)\n",
    "    \n",
    "    H = torch.zeros(bsz, m+1, m+1, dtype=x0.dtype, device=x0.device)\n",
    "    H[:,0,1:] = H[:,1:,0] = 1\n",
    "    y = torch.zeros(bsz, m+1, 1, dtype=x0.dtype, device=x0.device)\n",
    "    y[:,0] = 1\n",
    "    \n",
    "    res = []\n",
    "    for k in range(2, max_iter):\n",
    "        n = min(k, m)\n",
    "        G = F[:,:n]-X[:,:n]\n",
    "        H[:,1:n+1,1:n+1] = torch.bmm(G,G.transpose(1,2)) + lam*torch.eye(n, dtype=x0.dtype,device=x0.device)[None]\n",
    "        alpha = torch.solve(y[:,:n+1], H[:,:n+1,:n+1])[0][:, 1:n+1, 0]   # (bsz x n)\n",
    "        \n",
    "        X[:,k%m] = beta * (alpha[:,None] @ F[:,:n])[:,0] + (1-beta)*(alpha[:,None] @ X[:,:n])[:,0]\n",
    "        F[:,k%m] = f(X[:,k%m].view_as(x0)).view(bsz, -1)\n",
    "        res.append((F[:,k%m] - X[:,k%m]).norm().item()/(1e-5 + F[:,k%m].norm().item()))\n",
    "        if (res[-1] < tol):\n",
    "            break\n",
    "    return X[:,k%m].view_as(x0), res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e7a00-6af9-405f-9575-5b23d4a64b63",
   "metadata": {},
   "source": [
    "Simple resnet layer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c24da3-4c0f-4d4e-a08e-af7052e27c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d3dd20-421d-4fa8-9dc3-d4e548a60910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, n_channels, n_inner_channels, kernel_size=3, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, n_inner_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.conv2 = nn.Conv2d(n_inner_channels, n_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.norm1 = nn.GroupNorm(num_groups, n_inner_channels)\n",
    "        self.norm2 = nn.GroupNorm(num_groups, n_channels)\n",
    "        self.norm3 = nn.GroupNorm(num_groups, n_channels)\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        \n",
    "    def forward(self, z, x):\n",
    "        y = self.norm1(F.relu(self.conv1(z)))\n",
    "        return self.norm3(F.relu(z + self.norm2(x + self.conv2(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b79af3-ae63-4811-9654-5df76e3b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_23612\\2079614911.py:19: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:859.)\n",
      "  alpha = torch.solve(y[:,:n+1], H[:,:n+1,:n+1])[0][:, 1:n+1, 0]   # (bsz x n)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(10,64,32,32)\n",
    "f = ResNetLayer(64,128)\n",
    "out = anderson_resnet(lambda Z : f(Z,X), torch.zeros_like(X), tol=1e-4, beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ecd730-8568-4f8b-a816-5b262d808d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Relative residual')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.semilogy(out[1])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba46389-c542-409d-9ec7-f4527013f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers import broyden, anderson\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers.models.roberta.modeling_roberta import RobertaLayer, RobertaEmbeddings\n",
    "from transformers.models.roberta.configuration_roberta import RobertaConfig\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a4786f-bdf3-4543-9de7-eebbe8d56b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 2264, 5, 2335, 608, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "encoded = tokenizer(\"What the dog doing\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "babeda5c-5733-41a2-9027-1bea61a248e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEQRobertaLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.config =  RobertaConfig(is_decoder=False)\n",
    "        self.layer = RobertaLayer(self.config)\n",
    "        \n",
    "        self.f_solver = anderson\n",
    "        self.b_solver = broyden\n",
    "        self.f_thres = 100\n",
    "        self.b_thres = 100\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # output of robertalayer that we want is wrapped in tuple since extra elements are provided if is_decoder=True\n",
    "        f = lambda x: self.layer(x)[0]\n",
    "        \n",
    "        z0 = torch.zeros_like(hidden_states)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            z_star = self.f_solver(f, z0, threshold=self.f_thres)['result']\n",
    "            new_z_star = z_star\n",
    "\n",
    "        # (Prepare for) Backward pass\n",
    "        if self.training:\n",
    "            new_z_star = f(z_star.requires_grad_())\n",
    "\n",
    "            def backward_hook(grad):\n",
    "                if self.hook is not None:\n",
    "                    self.hook.remove()\n",
    "                    torch.cuda.synchronize()   # To avoid infinite recursion\n",
    "                # Compute the fixed point of yJ + grad, where J=J_f is the Jacobian of f at z_star\n",
    "                new_grad = self.b_solver(lambda y: autograd.grad(new_z_star, z_star, y, retain_graph=True)[0] + grad,\n",
    "                                         torch.zeros_like(grad), threshold=self.b_thres)['result']\n",
    "                return new_grad\n",
    "\n",
    "            self.hook = new_z_star.register_hook(backward_hook)\n",
    "        return (new_z_star,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde22272-e360-4fcb-85b7-63db8ef6273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEQRobertaLayer(\n",
       "  (layer): RobertaLayer(\n",
       "    (attention): RobertaAttention(\n",
       "      (self): RobertaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): RobertaSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): RobertaIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): RobertaOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 8, 768)\n",
    "model = DEQRobertaLayer()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df1e9fc-49a3-47d4-b997-f0c7f2add534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6298, -0.6063, -0.4628,  ...,  0.8799, -1.1862,  0.6208],\n",
       "         [-0.7252, -0.3282, -0.5845,  ...,  1.3895, -0.8281,  0.5945],\n",
       "         [-0.6202, -0.6439, -0.4796,  ...,  1.3834, -1.2490,  0.3822],\n",
       "         ...,\n",
       "         [-0.7294, -0.6659, -0.4969,  ...,  1.2708, -1.0152,  0.5147],\n",
       "         [-0.6478, -0.6944, -0.4950,  ...,  1.3217, -1.1240,  0.5177],\n",
       "         [-0.7039, -0.6700, -0.5919,  ...,  1.3319, -0.8063,  0.5152]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1feae05e-213b-4214-8d3a-0855631ce76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bertdeq\n",
    "import torch\n",
    "from transformers import RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e40fbbe-5e0c-40a4-b6df-cfa330efe473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 2264, 5, 2335, 608, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "#encoded = tokenizer(\"What the dog doing\", return_tensors='pt')\n",
    "#encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e793c0a2-9890-4fa2-af0e-d9fc0ccc9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'input_ids': torch.tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     2]]), 'attention_mask': torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa454ef5-1090-4f3f-baef-7729b59b1f48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DEQRobertaLayer(\n",
       "        (layer): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig(is_decoder=False)\n",
    "model = bertdeq.RobertaModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cb938f-4c5c-4baa-a08b-f48204404f4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\implicit-bert\\BertDEQ\\bertdeq.py:857\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    855\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 857\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    865\u001b[0m     embedding_output,\n\u001b[0;32m    866\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    874\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    875\u001b[0m )\n\u001b[0;32m    876\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\implicit-bert\\BertDEQ\\bertdeq.py:112\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    109\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    115\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bert-ode\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model(**inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
